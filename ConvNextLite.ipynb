{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWFbqnYf9ge8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(BasicCNN, self).__init__()\n",
        "        # First convolutional layer (input: 3 channels, output: 32 filters)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        # Second convolutional layer (input: 32 channels, output: 64 filters)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # Max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Fully connected layer (input: 64 * 8 * 8, output: 512)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        # Output layer\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Apply conv1 + ReLU + Pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Apply conv2 + ReLU + Pool\n",
        "        x = torch.flatten(x, 1)  # Flatten the tensor for fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # Fully connected layer with ReLU\n",
        "        x = self.fc2(x)  # Output layer\n",
        "        return x"
      ],
      "metadata": {
        "id": "oSsdiiD19mi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations to apply to the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalization\n",
        "])\n",
        "\n",
        "# Load full CIFAR-10 training and test datasets\n",
        "full_train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train into training + validation\n",
        "train_size = int(0.8 * len(full_train_data))  # 80% train\n",
        "val_size = len(full_train_data) - train_size  # 20% val\n",
        "train_data, val_data = random_split(full_train_data, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=256, shuffle=True, num_workers = 2, pin_memory = True)\n",
        "val_loader = DataLoader(val_data, batch_size=256, shuffle=False,num_workers = 2, pin_memory = True)\n",
        "test_loader = DataLoader(test_data, batch_size=256, shuffle=False,num_workers = 2, pin_memory = True)\n",
        "\n",
        "# # Instantiate the model\n",
        "model = BasicCNN(num_classes=10)\n",
        "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training function\n",
        "def train(model, train_loader, loss_function, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()  # Backpropagation\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        # Print statistics every epoch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct/total:.2f}%\")\n",
        "\n",
        "# Test function\n",
        "def test(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # No need to compute gradients during testing\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    print(f\"Test Accuracy: {100 * correct/total:.2f}%\")\n",
        "\n",
        "# Set device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Train the model\n",
        "train(model, train_loader, loss_function, optimizer, num_epochs=10)\n",
        "\n",
        "# # Test the model\n",
        "test(model, test_loader)"
      ],
      "metadata": {
        "id": "d4eYdjpt9sQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, build a resNet like model\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "     def __init__(self, in_channels, out_channels, downsample = None,stride = 1):\n",
        "            super(ResNetBlock, self).__init__()\n",
        "            self.expansion_ratio = 4\n",
        "            self.conv_layer1 = nn.Conv2d(in_channels, out_channels,kernel_size = 1, stride=1, padding = 0)\n",
        "            self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "            self.conv_layer2 = nn.Conv2d(out_channels, out_channels,kernel_size = 3, stride= stride, padding = 1)\n",
        "            self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "            self.conv_layer3 = nn.Conv2d(out_channels, out_channels*self.expansion_ratio,kernel_size = 1,\n",
        "                                         stride = 1, padding = 0)\n",
        "            self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion_ratio)\n",
        "            self.activation = nn.ReLU()\n",
        "            self.downsample = downsample\n",
        "\n",
        "     def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv_layer1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv_layer2(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv_layer3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNetLite(nn.Module):\n",
        "    #Pass the type of block,How many blocks per layer, RGB, number of output classes\n",
        "    def __init__(self,block, layers, image_channels, num_classes = 10):\n",
        "        super(ResNetLite,self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv_layer1 = nn.Conv2d(image_channels, 64, kernel_size = 7, stride = 2, padding = 3)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "\n",
        "        #ResNetLite layers go here:\n",
        "        self.layer1 = self._make_layer(block,layers[0], out_channels = 64, stride = 1)\n",
        "        self.layer2 = self._make_layer(block,layers[1], out_channels = 128, stride = 2)\n",
        "        self.layer3 = self._make_layer(block,layers[2], out_channels = 256, stride = 2)\n",
        "        self.layer4 = self._make_layer(block,layers[3], out_channels = 512, stride = 2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def _make_layer(self,block, num_blocks, out_channels, stride):\n",
        "        layers = []\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * 4:\n",
        "\n",
        "\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(block(self.in_channels, out_channels, downsample, stride ))\n",
        "        self.in_channels  = out_channels * 4\n",
        "        for i in range(num_blocks-1):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "def ResNet50Lite(image_channels = 3, num_classes = 10):\n",
        "    return ResNetLite(ResNetBlock, [3,4,6,3], image_channels, num_classes)\n",
        "\n",
        "def ResNet18Lite(image_channels = 3, num_classes = 10):\n",
        "    return ResNetLite(ResNetBlock, [2,2,2,2], image_channels, num_classes)\n",
        "\n",
        "\n",
        "def test50():\n",
        "    net = ResNet50Lite()\n",
        "    x = torch.randn(2,3,224,224)\n",
        "    y= net(x).to('cuda')\n",
        "    print(y.shape)\n",
        "\n",
        "def test18():\n",
        "    net = ResNet18Lite()\n",
        "    x = torch.randn(2,3,224,224)\n",
        "    y = net(x).to('cuda')\n",
        "    print(y.shape)\n",
        "\n",
        "\n",
        "test50()\n",
        "test18()"
      ],
      "metadata": {
        "id": "3Re_wQNR97Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and evaluating a ResNet50Lite\n",
        "\n",
        "model = ResNet18Lite().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Define scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
        "\n",
        "\n",
        "# Accuracy function\n",
        "def compute_accuracy(loader):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "# Variables to track best performance\n",
        "best_val_acc = 0.0\n",
        "best_model_wts = None\n",
        "\n",
        "\n",
        "#UNCOMMENT BEFORE SUBMITTING\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Compute accuracies\n",
        "    train_acc = compute_accuracy(train_loader)\n",
        "    val_acc = compute_accuracy(val_loader)\n",
        "    test_acc = compute_accuracy(test_loader)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {running_loss:.3f} | \"\n",
        "          f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    # Save the model if it improves on validation accuracy\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = model.state_dict()  # Save the best weights\n",
        "        torch.save(best_model_wts, 'resnet50lite_best_model.pth')  # Save to file\n",
        "\n",
        "    # Step scheduler based on validation accuracy (optional)\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "# After training, load the best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(\"Best model loaded from saved weights!\")"
      ],
      "metadata": {
        "id": "Mr4ufCX3-B8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New convnext with layer norm in it:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Channelwise LayerNorm wrapper\n",
        "class ChannelwiseLayerNorm(nn.Module):\n",
        "    def __init__(self, num_channels, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(num_channels, eps=eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Same shape as ConvNext model uses\n",
        "        # Convert [N, C, H, W] -> [N, H, W, C]\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.norm(x)\n",
        "        # Convert back [N, H, W, C] -> [N, C, H, W]\n",
        "        return x.permute(0, 3, 1, 2)\n",
        "\n",
        "# ConvNeXt-like Block\n",
        "class ConvNextBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=None, stride=1,\n",
        "                 use_inverted_bottleneck=False, use_gelu=False,\n",
        "                 use_large_kernels=False, use_layer_norm=False):\n",
        "        super(ConvNextBlock, self).__init__()\n",
        "        self.expansion_ratio = 4\n",
        "        self.downsample = downsample\n",
        "        self.use_inverted_bottleneck = use_inverted_bottleneck\n",
        "        self.use_large_kernels = use_large_kernels\n",
        "\n",
        "        self.activation = nn.GELU() if use_gelu else nn.ReLU()\n",
        "        kernel_size = 7 if self.use_large_kernels else 3\n",
        "        padding = kernel_size // 2\n",
        "\n",
        "        Norm = lambda c: ChannelwiseLayerNorm(c) if use_layer_norm else nn.BatchNorm2d(c)\n",
        "\n",
        "        if self.use_inverted_bottleneck:\n",
        "            expanded_channels = in_channels * self.expansion_ratio\n",
        "\n",
        "            self.expand = nn.Conv2d(in_channels, expanded_channels, kernel_size=1)\n",
        "            self.norm1 = Norm(expanded_channels)\n",
        "\n",
        "            self.depthwise_conv_layer = nn.Conv2d(\n",
        "                expanded_channels, expanded_channels, kernel_size=kernel_size,\n",
        "                stride=stride, padding=padding, groups=expanded_channels)\n",
        "            self.norm2 = Norm(expanded_channels)\n",
        "\n",
        "            self.project = nn.Conv2d(expanded_channels, out_channels * self.expansion_ratio, kernel_size=1)\n",
        "            self.norm3 = Norm(out_channels * self.expansion_ratio)\n",
        "        else:\n",
        "            self.conv_layer1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "            self.norm1 = Norm(out_channels)\n",
        "\n",
        "            self.conv_layer2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "            self.norm2 = Norm(out_channels)\n",
        "\n",
        "            self.conv_layer3 = nn.Conv2d(out_channels, out_channels * self.expansion_ratio, kernel_size=1,\n",
        "                                         stride=1, padding=0)\n",
        "            self.norm3 = Norm(out_channels * self.expansion_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        if self.use_inverted_bottleneck:\n",
        "            x = self.expand(x)\n",
        "            x = self.norm1(x)\n",
        "            x = self.activation(x)\n",
        "\n",
        "            x = self.depthwise_conv_layer(x)\n",
        "            x = self.norm2(x)\n",
        "            x = self.activation(x)\n",
        "\n",
        "            x = self.project(x)\n",
        "            x = self.norm3(x)\n",
        "        else:\n",
        "            x = self.conv_layer1(x)\n",
        "            x = self.norm1(x)\n",
        "            x = self.activation(x)\n",
        "\n",
        "            x = self.conv_layer2(x)\n",
        "            x = self.norm2(x)\n",
        "            x = self.activation(x)\n",
        "\n",
        "            x = self.conv_layer3(x)\n",
        "            x = self.norm3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvNextLite(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes=10,\n",
        "                 use_patchify_stem=False, use_gelu=False,\n",
        "                 use_inverted_bottleneck=False, use_large_kernels=False,\n",
        "                 use_layer_norm=False):\n",
        "        super(ConvNextLite, self).__init__()\n",
        "        self.use_patchify_stem = use_patchify_stem\n",
        "        self.use_gelu = use_gelu\n",
        "        self.use_inverted_bottleneck = use_inverted_bottleneck\n",
        "        self.use_large_kernels = use_large_kernels\n",
        "        self.use_layer_norm = use_layer_norm\n",
        "\n",
        "        Norm = lambda c: ChannelwiseLayerNorm(c) if use_layer_norm else nn.BatchNorm2d(c)\n",
        "\n",
        "        if self.use_patchify_stem:\n",
        "            self.conv_layer1 = nn.Conv2d(image_channels, 64, kernel_size=4, stride=4, padding=0)\n",
        "            self.norm1 = Norm(64)\n",
        "        else:\n",
        "            self.conv_layer1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "            self.norm1 = Norm(64)\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.activation = nn.GELU() if use_gelu else nn.ReLU()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        if not self.use_patchify_stem:\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_blocks, out_channels, stride):\n",
        "        layers = []\n",
        "        Norm = lambda c: ChannelwiseLayerNorm(c) if self.use_layer_norm else nn.BatchNorm2d(c)\n",
        "\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * 4:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride),\n",
        "                Norm(out_channels * 4)\n",
        "            )\n",
        "\n",
        "        layers.append(block(\n",
        "            self.in_channels, out_channels, downsample, stride,\n",
        "            use_inverted_bottleneck=self.use_inverted_bottleneck,\n",
        "            use_gelu=self.use_gelu,\n",
        "            use_large_kernels=self.use_large_kernels,\n",
        "            use_layer_norm=self.use_layer_norm))\n",
        "\n",
        "        self.in_channels = out_channels * 4\n",
        "        for _ in range(num_blocks - 1):\n",
        "            layers.append(block(\n",
        "                self.in_channels, out_channels,\n",
        "                use_inverted_bottleneck=self.use_inverted_bottleneck,\n",
        "                use_gelu=self.use_gelu,\n",
        "                use_large_kernels=self.use_large_kernels,\n",
        "                use_layer_norm=self.use_layer_norm))\n",
        "\n",
        "        return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "bJYN4pHs-J44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a ConvNextLite for testing\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"Model setup complete\")\n",
        "model = ConvNextLite(ConvNextBlock, [1,1,3,1], 3, use_patchify_stem=True, use_gelu=True, use_inverted_bottleneck=True, use_large_kernels=True, use_layer_norm=True)\n",
        "model = model.to(device)\n",
        "print(\"Model transferred to device\")\n",
        "\n",
        "# model = ConvNextLite(ConvNextBlock, [3,3,9,3], 3, use_patchify_stem = True, use_gelu = True, use_inverted_bottleneck = True, use_large_kernels = True, use_layer_norm = True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Define scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
        "\n",
        "\n",
        "# Accuracy function\n",
        "def compute_accuracy(loader):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "# Variables to track best performance\n",
        "best_val_acc = 0.0\n",
        "best_model_wts = None\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    # Compute accuracies\n",
        "    train_acc = compute_accuracy(train_loader)\n",
        "    val_acc = compute_accuracy(val_loader)\n",
        "    test_acc = compute_accuracy(test_loader)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {running_loss:.3f} | \"\n",
        "          f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    # Save the model if it improves on validation accuracy\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = model.state_dict()  # Save the best weights\n",
        "        torch.save(best_model_wts, 'all_ConvNextLite_model.pth')  # Save to file\n",
        "\n",
        "    # Step scheduler based on validation accuracy\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "# After training, load the best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(\"Best model loaded from saved weights!\")"
      ],
      "metadata": {
        "id": "gBsv6ZE9-OmG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
